{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9239b23-9719-4655-8c62-cf496d09c06b",
   "metadata": {},
   "source": [
    "# A100 7번 GPU 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e2b4fe-cff7-4ac5-b811-b3457ec1ca42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0d005c84b7416098426d79d6b04f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!git config --global credential.helper store\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2baadaec-ce84-4d5b-952e-03d6970e0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from IPython.display import Image, display, HTML\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53257d6d-bff8-4837-9779-64b5a5e36a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/grit_all_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4774f1a-20f7-4722-8759-32567c79fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(filename):\n",
    "    name_wo_ext = re.sub(r'\\.\\w+$', '', filename)\n",
    "    name_wo_ext = re.sub(r'\\(([^)]*)\\)', lambda m: m.group(1).replace(',', ''), name_wo_ext)\n",
    "    tokens = re.split(r'[_+()\\s]+', name_wo_ext)\n",
    "    tokens = [t for t in tokens if not re.search(r'\\d', t) and t]\n",
    "    return ', '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3578707-b3f6-4911-ac97-d64723db6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.columns = ['path', 'filename']\n",
    "df['keyword'] = df['filename'].apply(extract_keywords)\n",
    "df['path'] = df['path'].str.replace('\\\\', '/', regex=False)\n",
    "df = df.drop(['filename'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "514a4dcb-acdd-4638-8f18-0338971ea67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['keyword', 'path'],\n",
       "        num_rows: 110955\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict({'train': Dataset.from_pandas(df[['keyword', 'path']])})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b204cd-f961-4903-ad6a-d8b2ddf4a9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword': 'ITCRC, 기간연장협약서',\n",
       " 'path': 'Z:/1_일반행정/1_센터_규정_및_소개/1_설립_및_규정/1_ITCRC_협약서/ITCRC_기간연장협약서_200811.pdf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10acec64-cbef-4f05-9333-01fad6d2931f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword': '자산보관위탁기간연장약정서',\n",
       " 'path': 'Z:/1_일반행정/1_센터_규정_및_소개/1_설립_및_규정/1_ITCRC_협약서/자산보관위탁기간연장약정서_20090922.jpg'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b55f79e-b308-4865-80a2-45153edf1d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword': '자립화계획서',\n",
       " 'path': 'Z:/1_일반행정/1_센터_규정_및_소개/1_설립_및_규정/2_자립화_관련/GEMS자립화계획서/20100820_제출/발표자료/자립화계획서_ver01.pptx'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c81beab4-bbbd-40d4-8afc-b6a9da326e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75f3301b4304d8f8a582d27611b838c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = 'google/gemma-2b-it'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0afe792-7591-4b6e-939e-d7a380b95fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_before(keyword):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user', \n",
    "            'content': (\n",
    "                '아래는 키워드입니다.\\n\\n'\n",
    "                '해당 키워드에 맞는 문서 경로를 알려주세요.\\n'\n",
    "                f'keyword: {keyword}\\n'\n",
    "                'path:'\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    params = {'do_sample': True, 'temperature': 0.3, 'top_k': 40, 'top_p': 0.9, 'add_special_tokens': True}\n",
    "    outputs = pipe(prompt, **params)\n",
    "    result = outputs[0]['generated_text'][len(prompt):].strip()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "457e4988-c77d-4dde-9de3-9fb2002c19f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITCRC의 문서 경로는 다음과 같습니다.\n",
      "\n",
      "- ITCRC 홈페이지: path/to/itcrc.do\n",
      "- 기간연장협약서 관련 문서: path/to/itcrc/agreement.do\n"
     ]
    }
   ],
   "source": [
    "finetuning_before(dataset['train'][0]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7db138ef-9c1b-4b2d-920f-fa3109ef1de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드 자산보관위탁기간연장약정서는 다음과 같은 문서 경로에 존재합니다.\n",
      "\n",
      "* **법률정보시스템:** 자산보관위탁기간연장약정서 제3조\n",
      "* **국민은행 고유정보 공개규:** 자산보관위탁기간연장약정서 제3조\n",
      "* **국민은행 웹사이트:** 자산보관위탁기간연장약정서 제3조\n",
      "* **경찰서의 주소:** 경찰서의 주소를 포함한 지역 행사지도를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "finetuning_before(dataset['train'][4]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57255b30-8464-4f04-ac45-0edf1a37e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자립화계획서의 문서 경로는 다음과 같습니다.\n",
      "\n",
      "* **C:\\Users\\username\\Documents\\자립화계획서\\**\n",
      "\n",
      "이 경로는 사용자의 개인 문서 저장소의 \"자립화계획서\" 폴더에 위치합니다.\n"
     ]
    }
   ],
   "source": [
    "finetuning_before(dataset['train'][47]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30fd0213-9936-4d1c-978d-7bc9ae1ae790",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=6,\n",
    "    lora_alpha = 8,\n",
    "    lora_dropout = 0.05,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb2fa709-34a0-41a3-831f-1fcf36150d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c99ccdfe3d5463eb34a52b95d1f9d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\", quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cffa822-140c-4813-a791-8fe31c8bd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(keyword):\n",
    "    prompt = (\n",
    "        '아래는 키워드입니다.\\n\\n'\n",
    "        '해당 키워드에 맞는 문서 경로를 알려주세요.\\n'\n",
    "        f'keyword: {keyword}\\n'\n",
    "        'path:'\n",
    "    )\n",
    "    return [prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "032d1286-66f2-4255-a73c-2f127a8f4700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c3e582cf4348c7a6d36ee2468a8c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"outputs\",\n",
    "        max_steps=1000,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        warmup_steps=0.03,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        push_to_hub=False,\n",
    "        report_to='none',\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=generate_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e45ec6-63a2-434a-964f-a09bfe2c3a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 11:13, Epoch 36/38]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.857300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.1442343417406082, metrics={'train_runtime': 674.1872, 'train_samples_per_second': 5.933, 'train_steps_per_second': 1.483, 'total_flos': 2.4443766177792e+16, 'train_loss': 0.1442343417406082, 'epoch': 36.04})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcedecd3-e317-4499-8c10-5f236c928915",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAPTER_MODEL = 'lora_adapter'\n",
    "trainer.model.save_pretrained(ADAPTER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f47082-8d17-488c-8eaf-f4bed2b7360d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe94a991beea4244bea4b216bb549a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained('gemma-2b-it-sum-ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3fa2442-a578-406c-8836-7df3d1f1446f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3c48a781b84d988035047830f540a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = 'google/gemma-2b-it'\n",
    "FINETUNE_MODEL = './gemma-2b-it-sum-ko'\n",
    "\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, device_map={'':0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c618bd-638c-46e7-8c3f-5efdbaf47de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(keyword):\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=finetune_model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "    prompt = (\n",
    "        '아래는 키워드입니다.\\n\\n'\n",
    "        '해당 키워드에 맞는 문서 경로를 알려주세요.\\n'\n",
    "        f'keyword: {keyword}\\n'\n",
    "        'path:'\n",
    "    )    \n",
    "    output = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Keyword: {keyword}\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c907da9-b24a-42db-86c1-16bb1ea6f0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: ITCRC, 기간연장협약서\n",
      "아래는 키워드입니다.\n",
      "\n",
      "해당 키워드에 맞는 문서 경로를 알려주세요.\n",
      "keyword: ITCRC, 기간연장협약서\n",
      "path:\n"
     ]
    }
   ],
   "source": [
    "inference(dataset['train'][0]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16750afa-0b69-43a4-aaf0-de6708346c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: 자산보관위탁기간연장약정서\n",
      "아래는 키워드입니다.\n",
      "\n",
      "해당 키워드에 맞는 문서 경로를 알려주세요.\n",
      "keyword: 자산보관위탁기간연장약정서\n",
      "path:\n"
     ]
    }
   ],
   "source": [
    "inference(dataset['train'][4]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "688b2bcd-2c70-40c1-8c86-9a2bd01c5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: 자립화계획서\n",
      "아래는 키워드입니다.\n",
      "\n",
      "해당 키워드에 맞는 문서 경로를 알려주세요.\n",
      "keyword: 자립화계획서\n",
      "path:\n"
     ]
    }
   ],
   "source": [
    "inference(dataset['train'][47]['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e416b9f0-fd33-42c0-9cbf-21130ee624df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: 연가사용현황\n",
      "아래는 키워드입니다.\n",
      "\n",
      "해당 키워드에 맞는 문서 경로를 알려주세요.\n",
      "keyword: 연가사용현황\n",
      "path:\n"
     ]
    }
   ],
   "source": [
    "inference('연가사용현황')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
